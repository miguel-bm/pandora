{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process Deforestation Data from Hansen et al.\n",
    "\n",
    "In this notebook we will process the tree cover and deforestation data from Hansen et al. This map data is divided into 504 granules of 10x10 degrees, spanning from 60 degrees South to 80 degrees North"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "import PIL\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import json\n",
    "import multiprocessing\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.MAX_IMAGE_PIXELS = 2000000000  # Increase PIL image load limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(420, 1080)\n",
      "Each pixel will have a side of 37.065 km at the ecuator.\n",
      "Each granule will have 30 pixels to a side.\n"
     ]
    }
   ],
   "source": [
    "longitude_range = (-180, 180)\n",
    "latitude_range = (-60, 80)\n",
    "\n",
    "pixels_per_degree = 3\n",
    "\n",
    "longitude_size = (longitude_range[1] - longitude_range[0]) * pixels_per_degree\n",
    "latitude_size = (latitude_range[1] - latitude_range[0]) * pixels_per_degree\n",
    "granule_size = longitude_size / 36\n",
    "\n",
    "km_to_px_EC = 2 * np.pi * 6371 / 360 / pixels_per_degree\n",
    "\n",
    "img_common_size = (latitude_size, longitude_size)\n",
    "print(img_common_size)\n",
    "print(f\"Each pixel will have a side of {km_to_px_EC:.3f} km at the ecuator.\")\n",
    "print(f\"Each granule will have {granule_size:.0f} pixels to a side.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def granule_from_tif(tif_location, granule_size=30):\n",
    "    locator = (tif_location).stem[-8:]\n",
    "\n",
    "    with rasterio.open(tif_location) as dataset_reader:\n",
    "        # Upscale factor for achieving appropriate longitude dimension\n",
    "        upscale_factor = 1/(dataset_reader.width / granule_size)\n",
    "        # Downscale the dataset. Avg scaling to retain integer info\n",
    "        array = dataset_reader.read(\n",
    "            out_shape=(\n",
    "                dataset_reader.count,\n",
    "                int(dataset_reader.height * upscale_factor),\n",
    "                int(dataset_reader.width * upscale_factor)\n",
    "            ),\n",
    "            resampling=rasterio.enums.Resampling.average\n",
    "        ).squeeze()\n",
    "    \n",
    "    return (array, locator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def integrate_granule_to_base(base, granule, locator, lat_range=(-60, 80), granule_size=30):\n",
    "    lat = int(locator[:2]) * (1 if locator[2] == \"N\" else -1)\n",
    "    lon = int(locator[4:7]) * (1 if locator[7] == \"E\" else -1)\n",
    "    \n",
    "    lat_degs = lat_range[1] - lat_range[0]\n",
    "    \n",
    "    lat_min_id = int((80 - lat) / lat_degs * base.shape[0])\n",
    "    lat_max_id = lat_min_id + granule_size\n",
    "    lon_min_id = int((lon + 180) / 360 * base.shape[1])\n",
    "    lon_max_id = lon_min_id + granule_size\n",
    "        \n",
    "    base[lat_min_id:lat_max_id, lon_min_id:lon_max_id] = granule\n",
    "    \n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path(\"../data/raw/hansen\")\n",
    "output_folder = Path(\"../data/processed/hansen\")\n",
    "filename=\"Hansen_GFC-2018-v1.6_treecover2000_50N_010W.tif\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = np.zeros(img_common_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('../data/raw/hansen/Hansen_GFC-2018-v1.6_treecover2000_50N_020E.tif'),\n",
       " PosixPath('../data/raw/hansen/Hansen_GFC-2018-v1.6_treecover2000_50N_000E.tif'),\n",
       " PosixPath('../data/raw/hansen/Hansen_GFC-2018-v1.6_treecover2000_50N_010E.tif'),\n",
       " PosixPath('../data/raw/hansen/Hansen_GFC-2018-v1.6_treecover2000_50N_010W.tif')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data_folder.glob(\"*tree*.tif\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_outputs(array, name, location, value_type=\"real\", round_to=3):\n",
    "    with open(location/f\"{name}.pickle\", \"wb\") as file:\n",
    "        pickle.dump(array, file)\n",
    "    array_to_json(array, location/f\"{name}.json\", value_type=value_type, round_to=round_to)\n",
    "    plt.imsave(location/f\"{name}.jpg\", array, cmap=\"inferno\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all(layer, input_folder, output_folder, img_size=(420, 1080)):\n",
    "    tif_files = list(input_folder.glob(f\"*{layer}*.tif\"))\n",
    "    \n",
    "    max_processes = multiprocessing.cpu_count()\n",
    "    pool = multiprocessing.Pool(max_processes)\n",
    "    results = pool.map(granule_from_tif, tif_files)\n",
    "    \n",
    "    base = np.zeros(img_size)\n",
    "    for granule, locator in results:\n",
    "        base = integrate_granule_to_base(base, granule, locator)\n",
    "    array = base\n",
    "    save_outputs(array, layer, output_folder, value_type=\"real\", round_to=3)\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_json(array, destination, value_name=\"value\", value_type=\"real\", \n",
    "                  round_to=3, lon_range=(-180, 180), lat_range=(-60, 80), threshold=0, normalize_by=1.):\n",
    "    data = {}\n",
    "    fields = [\n",
    "        {\"name\": \"latitude\", \"format\": \"\", \"type\": \"real\"},\n",
    "        {\"name\": \"longitude\", \"format\": \"\", \"type\": \"real\"},\n",
    "        {\"name\": value_name, \"format\": \"\", \"type\": value_type},\n",
    "    ]\n",
    "    data[\"fields\"] = fields\n",
    "    data[\"rows\"] = array_to_coords(array, \n",
    "        round_to=round_to, \n",
    "        lon_range=lon_range, \n",
    "        lat_range=lat_range, \n",
    "        threshold=threshold,\n",
    "        normalize_by=normalize_by,\n",
    "    )\n",
    "    with open(destination, 'w') as file:\n",
    "        json.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_to_coords(array, round_to=3, lon_range=(-180, 180), lat_range=(-60, 80), threshold=0, normalize_by=1.):\n",
    "    norm = array/normalize_by\n",
    "    lats = np.arange(lat_range[1], lat_range[0], -(lat_range[1] - lat_range[0])/array.shape[0])\n",
    "    lons = np.arange(lon_range[0], lon_range[1],  (lon_range[1] - lon_range[0])/array.shape[1])\n",
    "    rows = list()\n",
    "    rows = [[round(float(lats[i]), round_to), \n",
    "             round(float(lons[j]), round_to), \n",
    "             round(float(norm[i, j]), round_to)]\n",
    "            for j in range(array.shape[1]) \n",
    "            for i in range(array.shape[0])\n",
    "            if array[i, j] > threshold]  # Do not store values below or equal to the threshold (e.g. zeroes)\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 791 ms, sys: 155 ms, total: 946 ms\n",
      "Wall time: 7.83 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "array = process_all(\"treecover2000\", data_folder, Path(\"../data/processed/forest\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
